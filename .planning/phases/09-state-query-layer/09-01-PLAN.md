---
phase: 09-state-query-layer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - hfs/state/__init__.py
  - hfs/state/models.py
  - hfs/state/manager.py
autonomous: true

must_haves:
  truths:
    - "StateManager subscribes to all events and updates internal state"
    - "RunSnapshot contains agent tree, negotiation state, token usage, and trace timeline"
    - "All models serialize to JSON via model_dump(mode='json')"
    - "Version number increments on each state change"
  artifacts:
    - path: "hfs/state/models.py"
      provides: "Pydantic snapshot models (AgentNode, TriadInfo, AgentTree, NegotiationSnapshot, TokenUsageSummary, TraceTimeline, RunSnapshot)"
      exports: ["AgentStatus", "AgentNode", "TriadInfo", "AgentTree", "SectionNegotiationState", "ContestEvent", "NegotiationSnapshot", "AgentTokenUsage", "PhaseTokenUsage", "TokenUsageSummary", "PhaseTimeline", "TraceTimeline", "RunSnapshot"]
    - path: "hfs/state/manager.py"
      provides: "StateManager class that processes events and maintains state"
      exports: ["StateManager"]
    - path: "hfs/state/__init__.py"
      provides: "Public module exports"
      contains: "StateManager"
  key_links:
    - from: "hfs/state/manager.py"
      to: "hfs/events/bus.py"
      via: "EventBus.subscribe('*')"
      pattern: "subscribe.*\\*"
    - from: "hfs/state/manager.py"
      to: "hfs/state/models.py"
      via: "imports snapshot models"
      pattern: "from hfs\\.state\\.models import"
---

<objective>
Create Pydantic snapshot models and StateManager for Phase 9 State & Query Layer.

Purpose: Enable UI widgets to query current HFS state via clean Pydantic models. StateManager subscribes to all events from Phase 8 EventBus and maintains indexed state that can be queried efficiently.

Output:
- hfs/state/models.py with composable Pydantic models
- hfs/state/manager.py with event-processing StateManager
- hfs/state/__init__.py with public exports
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-state-query-layer/09-CONTEXT.md
@.planning/phases/09-state-query-layer/09-RESEARCH.md

# Phase 8 deliverables
@hfs/events/models.py
@hfs/events/bus.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Pydantic snapshot models</name>
  <files>hfs/state/models.py, hfs/state/__init__.py</files>
  <action>
Create hfs/state/models.py with all snapshot models per RESEARCH.md patterns:

1. **AgentStatus** enum (str, Enum): idle, working, blocked, complete

2. **AgentNode** model:
   - agent_id: str
   - triad_id: str
   - role: str
   - status: AgentStatus = AgentStatus.IDLE
   - current_action: Optional[str] = None
   - progress: Optional[float] = None
   - started_at: Optional[datetime] = None
   - ended_at: Optional[datetime] = None
   - blocking_reason: Optional[str] = None
   - @computed_field duration_ms -> Optional[float]

3. **TriadInfo** model:
   - triad_id: str
   - preset: str (hierarchical, dialectic, consensus)
   - agents: list[AgentNode] = Field(default_factory=list)

4. **AgentTree** model:
   - triads: list[TriadInfo] = Field(default_factory=list)
   - @computed_field agent_index -> dict[str, AgentNode] (flat lookup)

5. **ContestEvent** model:
   - round: int
   - claimants: list[str]
   - resolution: Optional[str] = None (concede, arbiter)
   - winner: Optional[str] = None

6. **SectionNegotiationState** model:
   - section_name: str
   - status: str (unclaimed, contested, claimed, frozen)
   - owner: Optional[str] = None
   - claimants: list[str] = Field(default_factory=list)
   - contest_history: list[ContestEvent] = Field(default_factory=list)

7. **NegotiationSnapshot** model:
   - temperature: float = 1.0
   - round: int = 0
   - sections: list[SectionNegotiationState] = Field(default_factory=list)
   - @computed_field contested_count -> int

8. **AgentTokenUsage** model:
   - agent_id: str
   - prompt_tokens: int = 0
   - completion_tokens: int = 0
   - @computed_field total_tokens -> int

9. **PhaseTokenUsage** model:
   - phase_name: str
   - agents: list[AgentTokenUsage] = Field(default_factory=list)
   - @computed_field total_tokens -> int

10. **TokenUsageSummary** model:
    - by_phase: list[PhaseTokenUsage] = Field(default_factory=list)
    - by_agent: list[AgentTokenUsage] = Field(default_factory=list)
    - @computed_field total_tokens -> int

11. **PhaseTimeline** model:
    - phase_name: str
    - started_at: datetime
    - ended_at: Optional[datetime] = None
    - @computed_field duration_ms -> Optional[float]
    - @computed_field is_complete -> bool

12. **TraceTimeline** model:
    - run_id: str
    - started_at: datetime
    - ended_at: Optional[datetime] = None
    - phases: list[PhaseTimeline] = Field(default_factory=list)
    - @computed_field total_duration_ms -> Optional[float]

13. **RunSnapshot** model (composite):
    - version: int
    - run_id: str
    - agent_tree: AgentTree
    - negotiation: NegotiationSnapshot
    - usage: TokenUsageSummary
    - timeline: TraceTimeline

All models must:
- Use `mode='json'` serialization compatibility (datetime -> ISO string, enum -> value)
- Have docstrings explaining purpose
- Include __all__ exports

Create hfs/state/__init__.py exporting all models.
  </action>
  <verify>
python -c "from hfs.state.models import *; print('Models imported OK')"
python -c "from hfs.state.models import AgentNode, AgentStatus; import json; a = AgentNode(agent_id='a1', triad_id='t1', role='orchestrator'); print(json.dumps(a.model_dump(mode='json')))"
  </verify>
  <done>
All 13 Pydantic models created with computed_field decorators. Models serialize to JSON correctly. Module exports all models.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create StateManager with event processing</name>
  <files>hfs/state/manager.py, hfs/state/__init__.py</files>
  <action>
Create hfs/state/manager.py implementing StateManager class per RESEARCH.md:

```python
class StateManager:
    """Maintains HFS state computed from events.

    Subscribes to EventBus for all events and maintains indexed state
    for efficient queries. Supports version tracking for cache invalidation.
    """

    def __init__(self, event_bus: EventBus) -> None:
        """Initialize with event bus reference."""
        self._event_bus = event_bus
        self._version: int = 0
        self._run_id: Optional[str] = None

        # Indexed state
        self._agents: dict[str, AgentNode] = {}
        self._triads: dict[str, TriadInfo] = {}
        self._phases: dict[str, PhaseTimeline] = {}
        self._sections: dict[str, SectionNegotiationState] = {}
        self._agent_usage: dict[str, AgentTokenUsage] = {}
        self._phase_usage: dict[str, PhaseTokenUsage] = {}

        # Timeline tracking
        self._run_started_at: Optional[datetime] = None
        self._run_ended_at: Optional[datetime] = None
        self._negotiation_round: int = 0
        self._temperature: float = 1.0

        # Event history for delta queries (bounded)
        self._event_history: list[HFSEvent] = []
        self._max_history: int = 1000

        # Stream handle
        self._stream: Optional[EventStream] = None
        self._processing_task: Optional[asyncio.Task] = None

    @property
    def version(self) -> int:
        """Current state version for cache invalidation."""
        return self._version

    async def start(self) -> None:
        """Subscribe to all events and start processing."""
        self._stream = await self._event_bus.subscribe("*")
        self._processing_task = asyncio.create_task(self._process_events())

    async def stop(self) -> None:
        """Stop event processing and cleanup."""
        if self._stream:
            await self._event_bus.unsubscribe(self._stream)
        if self._processing_task:
            self._processing_task.cancel()
            try:
                await self._processing_task
            except asyncio.CancelledError:
                pass

    async def _process_events(self) -> None:
        """Process events from stream, updating state."""
        async for event in self._stream:
            self._apply_event(event)
            self._version += 1
            self._event_history.append(event)
            # Bound history size
            if len(self._event_history) > self._max_history:
                self._event_history.pop(0)

    def _apply_event(self, event: HFSEvent) -> None:
        """Update internal state based on event type."""
        # Dispatch based on event_type
        handlers = {
            "run.started": self._handle_run_started,
            "run.ended": self._handle_run_ended,
            "phase.started": self._handle_phase_started,
            "phase.ended": self._handle_phase_ended,
            "agent.started": self._handle_agent_started,
            "agent.ended": self._handle_agent_ended,
            "negotiation.claimed": self._handle_negotiation_claimed,
            "negotiation.contested": self._handle_negotiation_contested,
            "negotiation.resolved": self._handle_negotiation_resolved,
            "usage.recorded": self._handle_usage_recorded,
        }
        handler = handlers.get(event.event_type)
        if handler:
            handler(event)
```

Implement all handler methods:

1. **_handle_run_started**: Set run_id, run_started_at
2. **_handle_run_ended**: Set run_ended_at
3. **_handle_phase_started**: Create PhaseTimeline entry in _phases
4. **_handle_phase_ended**: Update PhaseTimeline with ended_at
5. **_handle_agent_started**: Create/update AgentNode with status=WORKING, ensure triad exists
6. **_handle_agent_ended**: Update AgentNode with status=COMPLETE, ended_at
7. **_handle_negotiation_claimed**: Update/create section with claimant
8. **_handle_negotiation_contested**: Update section status to contested, add to contest_history
9. **_handle_negotiation_resolved**: Update section owner, status to claimed, resolution in history
10. **_handle_usage_recorded**: Update agent and phase usage tracking

Add builder methods for snapshot models:

```python
def build_agent_tree(self) -> AgentTree:
    """Build current AgentTree from indexed state."""
    return AgentTree(triads=list(self._triads.values()))

def build_negotiation_snapshot(self) -> NegotiationSnapshot:
    """Build current NegotiationSnapshot."""
    return NegotiationSnapshot(
        temperature=self._temperature,
        round=self._negotiation_round,
        sections=list(self._sections.values()),
    )

def build_token_usage(self) -> TokenUsageSummary:
    """Build TokenUsageSummary from tracked usage."""
    return TokenUsageSummary(
        by_phase=list(self._phase_usage.values()),
        by_agent=list(self._agent_usage.values()),
    )

def build_trace_timeline(self) -> TraceTimeline:
    """Build TraceTimeline from tracked phases."""
    return TraceTimeline(
        run_id=self._run_id or "",
        started_at=self._run_started_at or datetime.utcnow(),
        ended_at=self._run_ended_at,
        phases=list(self._phases.values()),
    )

def build_snapshot(self) -> RunSnapshot:
    """Build complete RunSnapshot."""
    return RunSnapshot(
        version=self._version,
        run_id=self._run_id or "",
        agent_tree=self.build_agent_tree(),
        negotiation=self.build_negotiation_snapshot(),
        usage=self.build_token_usage(),
        timeline=self.build_trace_timeline(),
    )
```

Update hfs/state/__init__.py to export StateManager.
  </action>
  <verify>
python -c "from hfs.state import StateManager; print('StateManager imported OK')"
python -c "
import asyncio
from hfs.events import EventBus
from hfs.state import StateManager

async def test():
    bus = EventBus()
    mgr = StateManager(bus)
    await mgr.start()
    print(f'Version: {mgr.version}')
    snapshot = mgr.build_snapshot()
    print(f'Snapshot run_id: {snapshot.run_id}')
    await mgr.stop()
    print('StateManager start/stop OK')

asyncio.run(test())
"
  </verify>
  <done>
StateManager class created with:
- Event subscription via EventBus.subscribe("*")
- Handler methods for all event types
- Builder methods for all snapshot models
- Version tracking incremented on each event
- Bounded event history (1000 events max)
- Clean start/stop lifecycle
  </done>
</task>

</tasks>

<verification>
Run all verification commands:

```bash
# Import test
python -c "from hfs.state import StateManager, RunSnapshot, AgentTree, NegotiationSnapshot"

# JSON serialization test
python -c "
from hfs.state.models import RunSnapshot, AgentTree, NegotiationSnapshot, TokenUsageSummary, TraceTimeline
from datetime import datetime
import json

# Create minimal snapshot
snapshot = RunSnapshot(
    version=1,
    run_id='test-run',
    agent_tree=AgentTree(),
    negotiation=NegotiationSnapshot(),
    usage=TokenUsageSummary(),
    timeline=TraceTimeline(run_id='test-run', started_at=datetime.utcnow()),
)
# Must serialize to JSON
json_str = json.dumps(snapshot.model_dump(mode='json'))
print(f'Serialized OK: {len(json_str)} bytes')
"

# StateManager integration test
python -c "
import asyncio
from hfs.events import EventBus
from hfs.events.models import RunStartedEvent, AgentStartedEvent
from hfs.state import StateManager

async def test():
    bus = EventBus()
    mgr = StateManager(bus)
    await mgr.start()

    # Emit events
    await bus.emit(RunStartedEvent(run_id='r1'))
    await asyncio.sleep(0.1)  # Let event process

    assert mgr.version >= 1, 'Version should increment'
    snapshot = mgr.build_snapshot()
    assert snapshot.run_id == 'r1', 'Run ID should be set'

    await mgr.stop()
    print('Integration test passed')

asyncio.run(test())
"
```
</verification>

<success_criteria>
1. All Pydantic models created with proper computed_field decorators
2. All models serialize to JSON via model_dump(mode='json')
3. StateManager subscribes to EventBus and processes events
4. StateManager version increments on each event
5. StateManager builds all snapshot models correctly
6. Module exports all public types
</success_criteria>

<output>
After completion, create `.planning/phases/09-state-query-layer/09-01-SUMMARY.md`
</output>
