---
phase: 06-observability
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - hfs/core/orchestrator.py
  - hfs/tests/test_observability_orchestrator.py
autonomous: true

must_haves:
  truths:
    - "Run-level span wraps entire pipeline execution"
    - "Phase-level spans capture timing for all 9 HFS phases"
    - "Phase spans include success/error status attributes"
    - "Phase timing recorded via both span attributes and metrics API"
  artifacts:
    - path: "hfs/core/orchestrator.py"
      provides: "Instrumented orchestrator with OTel spans"
      contains: "tracer.start_as_current_span"
    - path: "hfs/tests/test_observability_orchestrator.py"
      provides: "Tests for orchestrator tracing"
      min_lines: 50
  key_links:
    - from: "hfs/core/orchestrator.py"
      to: "hfs/observability/tracing"
      via: "import get_tracer"
      pattern: "from.*observability.*import.*get_tracer"
    - from: "hfs/core/orchestrator.py"
      to: "hfs/observability/metrics"
      via: "import get_meter"
      pattern: "from.*observability.*import.*get_meter"
---

<objective>
Instrument HFSOrchestrator with OpenTelemetry tracing for the 9-phase pipeline.

Purpose: Capture the full execution hierarchy from run down to phases, enabling visibility into pipeline timing, success/failure rates, and phase-level debugging.

Output: Modified orchestrator.py with span instrumentation for all phases, plus integration tests.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-observability/06-CONTEXT.md
@.planning/phases/06-observability/06-RESEARCH.md
@.planning/phases/06-observability/06-01-SUMMARY.md
@hfs/core/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Instrument orchestrator run() with root span and phase spans</name>
  <files>hfs/core/orchestrator.py</files>
  <action>
Modify `hfs/core/orchestrator.py` to add OpenTelemetry instrumentation:

1. Add imports at top:
   ```python
   from ..observability import get_tracer, get_meter, setup_tracing, setup_metrics
   from opentelemetry.trace import Status, StatusCode
   ```

2. Add module-level tracer and meter (lazy initialization):
   ```python
   _tracer = None
   _meter = None
   _phase_duration = None
   _phase_success = None
   _phase_failure = None

   def _get_tracer():
       global _tracer
       if _tracer is None:
           _tracer = get_tracer("hfs.orchestrator")
       return _tracer

   def _get_phase_metrics():
       global _meter, _phase_duration, _phase_success, _phase_failure
       if _meter is None:
           _meter = get_meter("hfs.orchestrator")
           _phase_duration = _meter.create_histogram(
               "hfs.phase.duration",
               description="Duration of HFS pipeline phases",
               unit="s"
           )
           _phase_success = _meter.create_counter(
               "hfs.phase.success.count",
               description="Count of successful phase completions",
               unit="{execution}"
           )
           _phase_failure = _meter.create_counter(
               "hfs.phase.failure.count",
               description="Count of failed phase executions",
               unit="{execution}"
           )
       return _phase_duration, _phase_success, _phase_failure
   ```

3. In `run()` method, wrap entire execution with root span:
   ```python
   async def run(self, user_request: str) -> HFSResult:
       import uuid
       tracer = _get_tracer()
       run_id = str(uuid.uuid4())[:8]

       with tracer.start_as_current_span("hfs.run") as run_span:
           run_span.set_attribute("hfs.run.id", run_id)
           run_span.set_attribute("hfs.run.request_summary", user_request[:100])
           run_span.set_attribute("hfs.run.triad_count", len(self.config.triads))
           # ... rest of run() logic with phase spans
   ```

4. Wrap each phase (INPUT, SPAWN, DELIBERATION, CLAIMS, NEGOTIATION, FREEZE, EXECUTION, INTEGRATION, OUTPUT) with phase spans:
   ```python
   # Example for INPUT phase:
   with tracer.start_as_current_span("hfs.phase.input") as phase_span:
       phase_span.set_attribute("hfs.phase.name", "input")
       phase_start = time.time()
       try:
           # ... existing input phase code ...
           duration = time.time() - phase_start
           phase_span.set_attribute("hfs.phase.duration_s", duration)
           phase_span.set_attribute("hfs.phase.success", True)
           _record_phase_metrics("input", duration, success=True)
       except Exception as e:
           duration = time.time() - phase_start
           phase_span.record_exception(e)
           phase_span.set_status(Status(StatusCode.ERROR, str(e)))
           phase_span.set_attribute("hfs.phase.success", False)
           _record_phase_metrics("input", duration, success=False)
           raise
   ```

5. Add helper for recording phase metrics (dual span + metrics):
   ```python
   def _record_phase_metrics(phase_name: str, duration_s: float, success: bool):
       phase_duration, phase_success, phase_failure = _get_phase_metrics()
       phase_duration.record(duration_s, {"hfs.phase.name": phase_name})
       if success:
           phase_success.add(1, {"hfs.phase.name": phase_name})
       else:
           phase_failure.add(1, {"hfs.phase.name": phase_name})
   ```

6. Set final run span status based on result.success:
   ```python
   if result.success:
       run_span.set_status(Status(StatusCode.OK))
   else:
       run_span.set_status(Status(StatusCode.ERROR, result.error or "Unknown error"))
   ```

Phase names to instrument (9 total):
- input, spawn, deliberation, claims, negotiation, freeze, execution, integration, output

Keep existing phase_timings dict for backward compatibility, but also record via spans.
  </action>
  <verify>
Code review: orchestrator.py has:
- Imports from hfs.observability
- Root span "hfs.run" wrapping run() method
- Phase spans for all 9 phases with attributes
- Error handling with record_exception and set_status
- Metric recording for phase duration and success/failure counts
  </verify>
  <done>Orchestrator run() method instrumented with root span and 9 phase spans, each recording timing and success/failure status via spans and metrics.</done>
</task>

<task type="auto">
  <name>Task 2: Create orchestrator observability tests</name>
  <files>hfs/tests/test_observability_orchestrator.py</files>
  <action>
Create `hfs/tests/test_observability_orchestrator.py` with tests for orchestrator tracing:

1. Test fixture to capture spans:
   ```python
   from opentelemetry.sdk.trace import TracerProvider
   from opentelemetry.sdk.trace.export import SimpleSpanProcessor
   from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter

   @pytest.fixture
   def span_exporter():
       """Capture spans in memory for testing."""
       exporter = InMemorySpanExporter()
       provider = TracerProvider()
       provider.add_span_processor(SimpleSpanProcessor(exporter))
       trace.set_tracer_provider(provider)
       yield exporter
       exporter.clear()
   ```

2. Test that run() creates root span:
   ```python
   @pytest.mark.asyncio
   async def test_run_creates_root_span(span_exporter, mock_config):
       # Setup minimal orchestrator
       orchestrator = HFSOrchestrator(config_dict=mock_config, llm_client=MockLLM())
       result = await orchestrator.run("test request")

       spans = span_exporter.get_finished_spans()
       run_spans = [s for s in spans if s.name == "hfs.run"]
       assert len(run_spans) == 1
       assert run_spans[0].attributes.get("hfs.run.id") is not None
   ```

3. Test that all 9 phase spans are created:
   ```python
   @pytest.mark.asyncio
   async def test_all_phase_spans_created(span_exporter, mock_config):
       orchestrator = HFSOrchestrator(config_dict=mock_config, llm_client=MockLLM())
       await orchestrator.run("test request")

       spans = span_exporter.get_finished_spans()
       phase_names = {"input", "spawn", "deliberation", "claims", "negotiation",
                      "freeze", "execution", "integration", "output"}
       found_phases = set()
       for span in spans:
           if span.name.startswith("hfs.phase."):
               phase = span.name.replace("hfs.phase.", "")
               found_phases.add(phase)

       assert found_phases == phase_names
   ```

4. Test phase span has duration and success attributes:
   ```python
   @pytest.mark.asyncio
   async def test_phase_span_attributes(span_exporter, mock_config):
       orchestrator = HFSOrchestrator(config_dict=mock_config, llm_client=MockLLM())
       await orchestrator.run("test request")

       spans = span_exporter.get_finished_spans()
       input_span = [s for s in spans if s.name == "hfs.phase.input"][0]

       assert "hfs.phase.name" in input_span.attributes
       assert input_span.attributes["hfs.phase.name"] == "input"
       assert "hfs.phase.duration_s" in input_span.attributes
       assert "hfs.phase.success" in input_span.attributes
   ```

5. Mock config fixture with minimal valid config.

Use `pytest.mark.asyncio` for async tests.
  </action>
  <verify>
`pytest hfs/tests/test_observability_orchestrator.py -v` passes all tests.
  </verify>
  <done>Orchestrator observability tests pass, verifying root span creation, 9 phase spans, and correct span attributes.</done>
</task>

</tasks>

<verification>
1. Run orchestrator with test config and observe console span output:
   ```python
   from hfs.observability import setup_tracing
   setup_tracing()
   # Run orchestrator - should see hfs.run and hfs.phase.* spans in console
   ```

2. All 9 phases have corresponding spans with timing

3. Tests pass: `pytest hfs/tests/test_observability_orchestrator.py -v`

4. Span hierarchy is correct (phase spans are children of run span)
</verification>

<success_criteria>
- orchestrator.py imports from hfs.observability
- run() wrapped in "hfs.run" span with run_id attribute
- All 9 phases wrapped in "hfs.phase.{name}" spans
- Each phase span has: hfs.phase.name, hfs.phase.duration_s, hfs.phase.success attributes
- Errors recorded via span.record_exception() and set_status(ERROR)
- Phase metrics recorded: hfs.phase.duration histogram, hfs.phase.success/failure counters
- Tests verify span creation and attributes
</success_criteria>

<output>
After completion, create `.planning/phases/06-observability/06-02-SUMMARY.md`
</output>
