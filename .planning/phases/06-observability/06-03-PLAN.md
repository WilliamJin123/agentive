---
phase: 06-observability
plan: 03
type: execute
wave: 3
depends_on: ["06-01", "06-02"]
files_modified:
  - hfs/agno/teams/base.py
  - hfs/tests/test_observability_agents.py
autonomous: true

must_haves:
  truths:
    - "Triad-level span wraps each triad execution"
    - "Agent-level spans capture individual agent operations"
    - "Token usage (prompt + completion) recorded as span attributes"
    - "Agent spans include model name, provider, and tier attributes"
  artifacts:
    - path: "hfs/agno/teams/base.py"
      provides: "Instrumented AgnoTriad with OTel spans"
      contains: "tracer.start_as_current_span"
    - path: "hfs/tests/test_observability_agents.py"
      provides: "Tests for agent tracing and token tracking"
      min_lines: 60
  key_links:
    - from: "hfs/agno/teams/base.py"
      to: "hfs/observability/tracing"
      via: "import get_tracer"
      pattern: "from.*observability.*import"
    - from: "hfs/agno/teams/base.py"
      to: "agent response"
      via: "token extraction"
      pattern: "hfs\\.tokens\\.(prompt|completion)"
---

<objective>
Instrument AgnoTriad base class with OpenTelemetry tracing for triad and agent-level spans, including token tracking.

Purpose: Complete the 4-level span hierarchy (Run -> Phase -> Triad -> Agent) and capture token usage from LLM responses for cost tracking and debugging.

Output: Modified base.py with triad/agent span instrumentation and token recording, plus tests.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-observability/06-CONTEXT.md
@.planning/phases/06-observability/06-RESEARCH.md
@.planning/phases/06-observability/06-01-SUMMARY.md
@.planning/phases/06-observability/06-02-SUMMARY.md
@hfs/agno/teams/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add triad-level spans to AgnoTriad base class</name>
  <files>hfs/agno/teams/base.py</files>
  <action>
Modify `hfs/agno/teams/base.py` to add triad-level OpenTelemetry instrumentation:

1. Add imports at top:
   ```python
   from hfs.observability import get_tracer, get_meter
   from hfs.observability.tracing import truncate_prompt
   from opentelemetry.trace import Status, StatusCode
   ```

2. Add module-level tracer and metrics (lazy initialization):
   ```python
   _tracer = None
   _meter = None
   _triad_duration = None
   _agent_duration = None
   _tokens_prompt = None
   _tokens_completion = None

   def _get_tracer():
       global _tracer
       if _tracer is None:
           _tracer = get_tracer("hfs.agno.triad")
       return _tracer

   def _get_agent_metrics():
       global _meter, _triad_duration, _agent_duration, _tokens_prompt, _tokens_completion
       if _meter is None:
           _meter = get_meter("hfs.agno.triad")
           _triad_duration = _meter.create_histogram(
               "hfs.triad.duration", unit="s", description="Duration of triad execution"
           )
           _agent_duration = _meter.create_histogram(
               "hfs.agent.duration", unit="s", description="Duration of agent execution"
           )
           _tokens_prompt = _meter.create_counter(
               "hfs.tokens.prompt", unit="{token}", description="Prompt tokens used"
           )
           _tokens_completion = _meter.create_counter(
               "hfs.tokens.completion", unit="{token}", description="Completion tokens used"
           )
       return _triad_duration, _agent_duration, _tokens_prompt, _tokens_completion
   ```

3. Modify `_run_with_error_handling()` to wrap execution with triad span:
   ```python
   async def _run_with_error_handling(self, phase: str, prompt: str) -> Any:
       tracer = _get_tracer()
       triad_duration, agent_duration, tokens_prompt, tokens_completion = _get_agent_metrics()

       with tracer.start_as_current_span(f"hfs.triad.{self.config.id}") as triad_span:
           triad_span.set_attribute("hfs.triad.id", self.config.id)
           triad_span.set_attribute("hfs.triad.type", self.config.preset.value)
           triad_span.set_attribute("hfs.triad.phase", phase)
           triad_span.set_attribute("hfs.triad.prompt_snippet", truncate_prompt(prompt))

           triad_start = time.time()
           try:
               self._session_state.current_phase = phase
               response = await self.team.arun(prompt)

               duration = time.time() - triad_start
               triad_span.set_attribute("hfs.triad.duration_s", duration)
               triad_span.set_attribute("hfs.triad.success", True)
               triad_duration.record(duration, {"hfs.triad.id": self.config.id, "hfs.triad.phase": phase})

               # Extract and record token usage if available
               self._record_token_usage(triad_span, response)

               # Record success for escalation tracker
               if self.escalation_tracker is not None:
                   for role in self.agents.keys():
                       self.escalation_tracker.record_success(self.config.id, role)

               return response

           except Exception as e:
               duration = time.time() - triad_start
               triad_span.record_exception(e)
               triad_span.set_status(Status(StatusCode.ERROR, str(e)))
               triad_span.set_attribute("hfs.triad.success", False)
               triad_duration.record(duration, {"hfs.triad.id": self.config.id, "hfs.triad.phase": phase})

               # Record failure for escalation tracker
               if self.escalation_tracker is not None:
                   self.escalation_tracker.record_failure(self.config.id, "team")

               self._save_partial_progress(phase)

               raise TriadExecutionError(
                   triad_id=self.config.id,
                   phase=phase,
                   agent="unknown",
                   error=str(e),
                   partial_state=self._session_state.model_dump(),
               ) from e
   ```

4. Add token recording helper method:
   ```python
   def _record_token_usage(self, span, response: Any) -> None:
       """Record token usage from LLM response if available.

       Extracts usage data from Agno team response and records as span attributes.
       Per CONTEXT.md: Track prompt_tokens and completion_tokens separately.
       """
       triad_duration, agent_duration, tokens_prompt, tokens_completion = _get_agent_metrics()

       # Try to extract usage from response
       # Agno may store this in response.usage or response.messages[-1].usage
       usage = None
       if hasattr(response, 'usage') and response.usage:
           usage = response.usage
       elif hasattr(response, 'messages') and response.messages:
           last_msg = response.messages[-1]
           if hasattr(last_msg, 'usage') and last_msg.usage:
               usage = last_msg.usage

       if usage:
           prompt_tokens = getattr(usage, 'prompt_tokens', 0) or 0
           completion_tokens = getattr(usage, 'completion_tokens', 0) or 0

           span.set_attribute("hfs.tokens.prompt", prompt_tokens)
           span.set_attribute("hfs.tokens.completion", completion_tokens)
           span.set_attribute("hfs.tokens.total", prompt_tokens + completion_tokens)

           # Record metrics
           labels = {"hfs.triad.id": self.config.id}
           tokens_prompt.add(prompt_tokens, labels)
           tokens_completion.add(completion_tokens, labels)
   ```

5. Add import for time module if not present:
   ```python
   import time
   ```

The triad spans will be children of the phase spans from orchestrator (via context propagation).
  </action>
  <verify>
Code review: base.py has:
- Imports from hfs.observability
- Triad span "hfs.triad.{id}" in _run_with_error_handling
- Token usage extraction and recording
- Span attributes for triad id, type, phase, prompt snippet, duration, success
- Metrics recording for triad duration and token counts
  </verify>
  <done>AgnoTriad base class instrumented with triad-level spans, token tracking from LLM responses, and metrics recording.</done>
</task>

<task type="auto">
  <name>Task 2: Add agent-level span support to AgnoTriad</name>
  <files>hfs/agno/teams/base.py</files>
  <action>
Add agent-level span creation for finer granularity. This is within AgnoTriad and wraps individual agent calls if the team exposes them.

Since Agno's team.arun() handles agent coordination internally, we can add agent-level attributes to the triad span AND create a helper that subclasses can use.

1. Add method for recording agent execution (can be called by subclasses if they override _run_with_error_handling):
   ```python
   def _create_agent_span_context(self, role: str, model_name: str = None, provider: str = None):
       """Create context manager for agent-level spans.

       Can be used by subclasses for finer-grained tracing if they
       override execution methods to call agents individually.

       Args:
           role: Agent role name (orchestrator, worker_a, etc.)
           model_name: Optional model name for the agent
           provider: Optional provider name

       Returns:
           Context manager that creates agent span
       """
       from contextlib import contextmanager
       tracer = _get_tracer()
       triad_duration, agent_duration, tokens_prompt, tokens_completion = _get_agent_metrics()

       @contextmanager
       def agent_span():
           with tracer.start_as_current_span(f"hfs.agent.{role}") as span:
               span.set_attribute("hfs.agent.role", role)
               span.set_attribute("hfs.agent.triad_id", self.config.id)
               if model_name:
                   span.set_attribute("hfs.agent.model", model_name)
               if provider:
                   span.set_attribute("hfs.agent.provider", provider)

               start = time.time()
               try:
                   yield span
                   duration = time.time() - start
                   span.set_attribute("hfs.agent.duration_s", duration)
                   span.set_attribute("hfs.agent.success", True)
                   agent_duration.record(duration, {"hfs.agent.role": role, "hfs.triad.id": self.config.id})
               except Exception as e:
                   duration = time.time() - start
                   span.record_exception(e)
                   span.set_status(Status(StatusCode.ERROR, str(e)))
                   span.set_attribute("hfs.agent.success", False)
                   agent_duration.record(duration, {"hfs.agent.role": role, "hfs.triad.id": self.config.id})
                   raise

       return agent_span()
   ```

2. Record agent roles in the triad span as a list attribute:
   In _run_with_error_handling, after creating the triad span:
   ```python
   triad_span.set_attribute("hfs.triad.agent_roles", list(self.agents.keys()))
   ```

3. Add model information from model_selector if available:
   ```python
   # If model_selector available, record tier info
   if self.model_selector:
       lead_role = list(self.agents.keys())[0]  # e.g., "orchestrator"
       tier = self.model_selector.get_current_tier(self.config.id, lead_role)
       if tier:
           triad_span.set_attribute("hfs.triad.tier", tier)
   ```

This provides the foundation for agent-level spans while keeping the current team.arun() approach working.
  </action>
  <verify>
Code review: base.py has:
- _create_agent_span_context() method for subclass use
- Agent roles recorded in triad span
- Optional tier information from model_selector
  </verify>
  <done>Agent-level span helper method available for subclasses, agent roles recorded in triad span attributes.</done>
</task>

<task type="auto">
  <name>Task 3: Create agent observability tests</name>
  <files>hfs/tests/test_observability_agents.py</files>
  <action>
Create `hfs/tests/test_observability_agents.py` with tests for agent tracing:

1. Test fixture to capture spans (similar to orchestrator tests):
   ```python
   import pytest
   from opentelemetry import trace
   from opentelemetry.sdk.trace import TracerProvider
   from opentelemetry.sdk.trace.export import SimpleSpanProcessor
   from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter
   from unittest.mock import Mock, AsyncMock, MagicMock

   @pytest.fixture
   def span_exporter():
       exporter = InMemorySpanExporter()
       provider = TracerProvider()
       provider.add_span_processor(SimpleSpanProcessor(exporter))
       trace.set_tracer_provider(provider)
       yield exporter
       exporter.clear()
   ```

2. Test that triad execution creates triad span:
   ```python
   @pytest.fixture
   def mock_model_selector():
       selector = Mock()
       selector.get_model.return_value = Mock()  # Mock Agno model
       selector.get_current_tier.return_value = "general"
       return selector

   @pytest.fixture
   def mock_spec():
       spec = Mock()
       return spec

   @pytest.mark.asyncio
   async def test_triad_span_created(span_exporter, mock_model_selector, mock_spec):
       # Create a concrete subclass for testing
       from hfs.agno.teams.hierarchical import HierarchicalAgnoTriad
       from hfs.core.triad import TriadConfig, TriadPreset

       config = TriadConfig(
           id="test-triad",
           preset=TriadPreset.HIERARCHICAL,
           scope_primary=["header"],
           objectives=["Test objective"],
       )

       # Mock the team.arun to return a simple response
       triad = HierarchicalAgnoTriad(config, mock_model_selector, mock_spec)
       triad.team.arun = AsyncMock(return_value="test response")

       await triad.deliberate("test request", {"sections": {}})

       spans = span_exporter.get_finished_spans()
       triad_spans = [s for s in spans if s.name.startswith("hfs.triad.")]
       assert len(triad_spans) >= 1
       assert triad_spans[0].attributes.get("hfs.triad.id") == "test-triad"
   ```

3. Test triad span has required attributes:
   ```python
   @pytest.mark.asyncio
   async def test_triad_span_attributes(span_exporter, mock_model_selector, mock_spec):
       from hfs.agno.teams.hierarchical import HierarchicalAgnoTriad
       from hfs.core.triad import TriadConfig, TriadPreset

       config = TriadConfig(
           id="attr-test",
           preset=TriadPreset.HIERARCHICAL,
           scope_primary=["header"],
           objectives=["Test"],
       )

       triad = HierarchicalAgnoTriad(config, mock_model_selector, mock_spec)
       triad.team.arun = AsyncMock(return_value="response")

       await triad.deliberate("test request", {"sections": {}})

       spans = span_exporter.get_finished_spans()
       triad_span = [s for s in spans if s.name.startswith("hfs.triad.")][0]

       assert "hfs.triad.id" in triad_span.attributes
       assert "hfs.triad.type" in triad_span.attributes
       assert "hfs.triad.phase" in triad_span.attributes
       assert triad_span.attributes["hfs.triad.phase"] == "deliberation"
   ```

4. Test token usage recording (mock response with usage):
   ```python
   @pytest.mark.asyncio
   async def test_token_usage_recorded(span_exporter, mock_model_selector, mock_spec):
       from hfs.agno.teams.hierarchical import HierarchicalAgnoTriad
       from hfs.core.triad import TriadConfig, TriadPreset

       config = TriadConfig(
           id="token-test",
           preset=TriadPreset.HIERARCHICAL,
           scope_primary=["header"],
           objectives=["Test"],
       )

       # Mock response with usage data
       mock_response = Mock()
       mock_response.usage = Mock()
       mock_response.usage.prompt_tokens = 100
       mock_response.usage.completion_tokens = 50

       triad = HierarchicalAgnoTriad(config, mock_model_selector, mock_spec)
       triad.team.arun = AsyncMock(return_value=mock_response)

       await triad.deliberate("test request", {"sections": {}})

       spans = span_exporter.get_finished_spans()
       triad_span = [s for s in spans if s.name.startswith("hfs.triad.")][0]

       # Token attributes should be set
       assert triad_span.attributes.get("hfs.tokens.prompt") == 100
       assert triad_span.attributes.get("hfs.tokens.completion") == 50
       assert triad_span.attributes.get("hfs.tokens.total") == 150
   ```

5. Test error handling creates error span:
   ```python
   @pytest.mark.asyncio
   async def test_error_creates_error_span(span_exporter, mock_model_selector, mock_spec):
       from hfs.agno.teams.hierarchical import HierarchicalAgnoTriad
       from hfs.core.triad import TriadConfig, TriadPreset
       from hfs.agno.teams.schemas import TriadExecutionError

       config = TriadConfig(
           id="error-test",
           preset=TriadPreset.HIERARCHICAL,
           scope_primary=["header"],
           objectives=["Test"],
       )

       triad = HierarchicalAgnoTriad(config, mock_model_selector, mock_spec)
       triad.team.arun = AsyncMock(side_effect=RuntimeError("Test error"))

       with pytest.raises(TriadExecutionError):
           await triad.deliberate("test request", {"sections": {}})

       spans = span_exporter.get_finished_spans()
       triad_span = [s for s in spans if s.name.startswith("hfs.triad.")][0]

       assert triad_span.attributes.get("hfs.triad.success") == False
       # Span status should be ERROR
       from opentelemetry.trace import StatusCode
       assert triad_span.status.status_code == StatusCode.ERROR
   ```

6. Test agent span helper method:
   ```python
   @pytest.mark.asyncio
   async def test_agent_span_context_manager(span_exporter, mock_model_selector, mock_spec):
       from hfs.agno.teams.hierarchical import HierarchicalAgnoTriad
       from hfs.core.triad import TriadConfig, TriadPreset

       config = TriadConfig(
           id="agent-span-test",
           preset=TriadPreset.HIERARCHICAL,
           scope_primary=["header"],
           objectives=["Test"],
       )

       triad = HierarchicalAgnoTriad(config, mock_model_selector, mock_spec)

       # Use the agent span context manager directly
       with triad._create_agent_span_context("orchestrator", model_name="gpt-4", provider="openai"):
           pass  # Simulate agent work

       spans = span_exporter.get_finished_spans()
       agent_spans = [s for s in spans if s.name.startswith("hfs.agent.")]
       assert len(agent_spans) >= 1
       assert agent_spans[0].attributes.get("hfs.agent.role") == "orchestrator"
       assert agent_spans[0].attributes.get("hfs.agent.model") == "gpt-4"
   ```
  </action>
  <verify>
`pytest hfs/tests/test_observability_agents.py -v` passes all tests.
  </verify>
  <done>Agent observability tests pass, verifying triad span creation, attributes, token recording, error handling, and agent span helper.</done>
</task>

</tasks>

<verification>
1. Run a triad execution and observe console span output showing triad span nested under phase span

2. Token usage attributes appear in triad spans when response has usage data

3. Tests pass: `pytest hfs/tests/test_observability_agents.py -v`

4. Full 4-level hierarchy visible: hfs.run -> hfs.phase.* -> hfs.triad.* when running orchestrator
</verification>

<success_criteria>
- base.py imports from hfs.observability
- _run_with_error_handling() wrapped in "hfs.triad.{id}" span
- Triad span has: hfs.triad.id, hfs.triad.type, hfs.triad.phase, hfs.triad.prompt_snippet, hfs.triad.duration_s, hfs.triad.success
- Token usage extracted from response.usage and recorded as: hfs.tokens.prompt, hfs.tokens.completion, hfs.tokens.total
- Metrics recorded: hfs.triad.duration histogram, hfs.tokens.prompt/completion counters
- Error cases set span status to ERROR and record exception
- Agent-level span helper _create_agent_span_context() available for subclass use
- Agent roles recorded in triad span as hfs.triad.agent_roles attribute
- Tests verify span creation, attributes, token recording, error handling, and agent span helper
</success_criteria>

<output>
After completion, create `.planning/phases/06-observability/06-03-SUMMARY.md`
</output>
